{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0839341a867caa07575d20a58f7ee9237d10d4b3d92142207c9cff347c278cde8",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistics model\n",
    "mp_drawing = mp.solutions.drawing_utils #drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    #Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                                mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "\n",
    "def get_keypoints(results):\n",
    "    try:\n",
    "        pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten()\n",
    "    except AttributeError:\n",
    "        pose = np.zeros(132)\n",
    "\n",
    "    try:\n",
    "        face = np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten()\n",
    "    except AttributeError:\n",
    "        face = np.zeros(468*3)\n",
    "\n",
    "    try:\n",
    "        lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten()\n",
    "    except AttributeError:\n",
    "        lh = np.zeros(63)\n",
    "\n",
    "    try:\n",
    "        rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten()\n",
    "    except AttributeError:\n",
    "        rh = np.zeros(63)\n",
    "\n",
    "    return np.concatenate([pose, face, lh, rh])\n"
   ]
  },
  {
   "source": [
    "Creating data folders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('ASL_ALPHABET')\n",
    "\n",
    "alphabets = np.array(['A', 'B', 'C'])\n",
    "\n",
    "no_sequences, sequence_length = 30,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alphabet in alphabets:\n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, alphabet, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "alpha_visted = set()\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for alphabet in alphabets:\n",
    "        for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                if frame_num == 0:\n",
    "\n",
    "                    if alphabet not in alpha_visted:\n",
    "                        cv2.putText(image, 'STARTING \\'{}\\' COLLECTION'.format(alphabet), (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "                        alpha_visted.add(alphabet)\n",
    "                    else:     \n",
    "                       cv2.putText(image, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for Alphabet \\'{}\\' Video Number: {}'.format(alphabet, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(1000) \n",
    "\n",
    "                else:\n",
    "                    cv2.putText(image,'Collecting frames for Alphabet \\'{}\\' Video Number: {}'.format(alphabet, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                np.save(os.path.join(DATA_PATH, alphabet, str(sequence), str(frame_num)), get_keypoints(results))\n",
    "                \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_labels = {alpha:label for label, alpha in enumerate(alphabets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "alpha_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [],[]\n",
    "for alpha in alphabets:\n",
    "    for seq in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, alpha, str(seq), '{}.npy'.format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(alpha_labels[alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(alphabets.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9374\n",
      "Epoch 2387/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3424 - categorical_accuracy: 0.9491\n",
      "Epoch 2388/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3412 - categorical_accuracy: 0.8963\n",
      "Epoch 2389/5000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3379 - categorical_accuracy: 0.9413\n",
      "Epoch 2390/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3084 - categorical_accuracy: 0.9354\n",
      "Epoch 2391/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3285 - categorical_accuracy: 0.9198\n",
      "Epoch 2392/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3604 - categorical_accuracy: 0.8552\n",
      "Epoch 2393/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.3429 - categorical_accuracy: 0.9100\n",
      "Epoch 2394/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3567 - categorical_accuracy: 0.8297\n",
      "Epoch 2395/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.3299 - categorical_accuracy: 0.9159\n",
      "Epoch 2396/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3364 - categorical_accuracy: 0.9041\n",
      "Epoch 2397/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3585 - categorical_accuracy: 0.8551\n",
      "Epoch 2398/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.4734 - categorical_accuracy: 0.7378\n",
      "Epoch 2399/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3725 - categorical_accuracy: 0.8591\n",
      "Epoch 2400/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.4290 - categorical_accuracy: 0.7730\n",
      "Epoch 2401/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4230 - categorical_accuracy: 0.8318\n",
      "Epoch 2402/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.5038 - categorical_accuracy: 0.7085\n",
      "Epoch 2403/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3964 - categorical_accuracy: 0.8415\n",
      "Epoch 2404/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4036 - categorical_accuracy: 0.8748\n",
      "Epoch 2405/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3219 - categorical_accuracy: 0.9491\n",
      "Epoch 2406/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3488 - categorical_accuracy: 0.8982\n",
      "Epoch 2407/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3204 - categorical_accuracy: 0.9315\n",
      "Epoch 2408/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3317 - categorical_accuracy: 0.8943\n",
      "Epoch 2409/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2891 - categorical_accuracy: 0.9784\n",
      "Epoch 2410/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2996 - categorical_accuracy: 0.9159\n",
      "Epoch 2411/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.4163 - categorical_accuracy: 0.8220\n",
      "Epoch 2412/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.4516 - categorical_accuracy: 0.7750\n",
      "Epoch 2413/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3408 - categorical_accuracy: 0.9413\n",
      "Epoch 2414/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3342 - categorical_accuracy: 0.9041\n",
      "Epoch 2415/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2677 - categorical_accuracy: 0.9491\n",
      "Epoch 2416/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3274 - categorical_accuracy: 0.9198\n",
      "Epoch 2417/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3201 - categorical_accuracy: 0.8924\n",
      "Epoch 2418/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3688 - categorical_accuracy: 0.8298\n",
      "Epoch 2419/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2827 - categorical_accuracy: 0.9256\n",
      "Epoch 2420/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2960 - categorical_accuracy: 0.9315\n",
      "Epoch 2421/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2886 - categorical_accuracy: 0.9648\n",
      "Epoch 2422/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2741 - categorical_accuracy: 0.9726\n",
      "Epoch 2423/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2570 - categorical_accuracy: 0.9569\n",
      "Epoch 2424/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2764 - categorical_accuracy: 0.9393\n",
      "Epoch 2425/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2771 - categorical_accuracy: 0.9452\n",
      "Epoch 2426/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2854 - categorical_accuracy: 0.9530\n",
      "Epoch 2427/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2860 - categorical_accuracy: 0.9432\n",
      "Epoch 2428/5000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2898 - categorical_accuracy: 0.9198\n",
      "Epoch 2429/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2732 - categorical_accuracy: 0.9511\n",
      "Epoch 2430/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2692 - categorical_accuracy: 0.9472\n",
      "Epoch 2431/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2637 - categorical_accuracy: 0.9198\n",
      "Epoch 2432/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2535 - categorical_accuracy: 0.9413\n",
      "Epoch 2433/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2682 - categorical_accuracy: 0.9276\n",
      "Epoch 2434/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2317 - categorical_accuracy: 0.9491\n",
      "Epoch 2435/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2673 - categorical_accuracy: 0.9335\n",
      "Epoch 2436/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2565 - categorical_accuracy: 0.9413\n",
      "Epoch 2437/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2251 - categorical_accuracy: 0.9687\n",
      "Epoch 2438/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2425 - categorical_accuracy: 0.9569\n",
      "Epoch 2439/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2639 - categorical_accuracy: 0.9354\n",
      "Epoch 2440/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3227 - categorical_accuracy: 0.8885\n",
      "Epoch 2441/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3019 - categorical_accuracy: 0.9256\n",
      "Epoch 2442/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3076 - categorical_accuracy: 0.9022\n",
      "Epoch 2443/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2425 - categorical_accuracy: 0.9413\n",
      "Epoch 2444/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2829 - categorical_accuracy: 0.9237\n",
      "Epoch 2445/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2338 - categorical_accuracy: 0.9491\n",
      "Epoch 2446/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2258 - categorical_accuracy: 0.9648\n",
      "Epoch 2447/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2517 - categorical_accuracy: 0.9178\n",
      "Epoch 2448/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2373 - categorical_accuracy: 0.9569\n",
      "Epoch 2449/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2282 - categorical_accuracy: 0.9608\n",
      "Epoch 2450/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2356 - categorical_accuracy: 0.9472\n",
      "Epoch 2451/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.4337 - categorical_accuracy: 0.7319\n",
      "Epoch 2452/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5364 - categorical_accuracy: 0.6949\n",
      "Epoch 2453/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.5526 - categorical_accuracy: 0.6693\n",
      "Epoch 2454/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.4391 - categorical_accuracy: 0.8257\n",
      "Epoch 2455/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.4263 - categorical_accuracy: 0.8297\n",
      "Epoch 2456/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3650 - categorical_accuracy: 0.8122\n",
      "Epoch 2457/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.6479 - categorical_accuracy: 0.6107\n",
      "Epoch 2458/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.6089 - categorical_accuracy: 0.6947\n",
      "Epoch 2459/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3118 - categorical_accuracy: 0.8942\n",
      "Epoch 2460/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3127 - categorical_accuracy: 0.8708\n",
      "Epoch 2461/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2787 - categorical_accuracy: 0.9589\n",
      "Epoch 2462/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2471 - categorical_accuracy: 0.9472\n",
      "Epoch 2463/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2744 - categorical_accuracy: 0.9472\n",
      "Epoch 2464/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2559 - categorical_accuracy: 0.9315\n",
      "Epoch 2465/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2542 - categorical_accuracy: 0.9491\n",
      "Epoch 2466/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2529 - categorical_accuracy: 0.9569\n",
      "Epoch 2467/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2180 - categorical_accuracy: 0.9432\n",
      "Epoch 2468/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2084 - categorical_accuracy: 0.9530\n",
      "Epoch 2469/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2292 - categorical_accuracy: 0.9550\n",
      "Epoch 2470/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2062 - categorical_accuracy: 0.9687\n",
      "Epoch 2471/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2806 - categorical_accuracy: 0.9119\n",
      "Epoch 2472/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2570 - categorical_accuracy: 0.9472\n",
      "Epoch 2473/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2126 - categorical_accuracy: 0.9569\n",
      "Epoch 2474/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2331 - categorical_accuracy: 0.9608\n",
      "Epoch 2475/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2654 - categorical_accuracy: 0.9276\n",
      "Epoch 2476/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2149 - categorical_accuracy: 0.9550\n",
      "Epoch 2477/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1947 - categorical_accuracy: 0.9608\n",
      "Epoch 2478/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1936 - categorical_accuracy: 0.9667\n",
      "Epoch 2479/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2030 - categorical_accuracy: 0.9569\n",
      "Epoch 2480/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2187 - categorical_accuracy: 0.9530\n",
      "Epoch 2481/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1809 - categorical_accuracy: 0.9745\n",
      "Epoch 2482/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2132 - categorical_accuracy: 0.9491\n",
      "Epoch 2483/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3417 - categorical_accuracy: 0.8709\n",
      "Epoch 2484/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2379 - categorical_accuracy: 0.9452\n",
      "Epoch 2485/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2482 - categorical_accuracy: 0.9354\n",
      "Epoch 2486/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2072 - categorical_accuracy: 0.9687\n",
      "Epoch 2487/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2036 - categorical_accuracy: 0.9530\n",
      "Epoch 2488/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1807 - categorical_accuracy: 0.9667\n",
      "Epoch 2489/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2025 - categorical_accuracy: 0.9550\n",
      "Epoch 2490/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2017 - categorical_accuracy: 0.9491\n",
      "Epoch 2491/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1987 - categorical_accuracy: 0.9667\n",
      "Epoch 2492/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2208 - categorical_accuracy: 0.9628\n",
      "Epoch 2493/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2477 - categorical_accuracy: 0.9374\n",
      "Epoch 2494/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2342 - categorical_accuracy: 0.9452\n",
      "Epoch 2495/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2104 - categorical_accuracy: 0.9765\n",
      "Epoch 2496/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2413 - categorical_accuracy: 0.9276\n",
      "Epoch 2497/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2306 - categorical_accuracy: 0.9550\n",
      "Epoch 2498/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1977 - categorical_accuracy: 0.9550\n",
      "Epoch 2499/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1932 - categorical_accuracy: 0.9804\n",
      "Epoch 2500/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2419 - categorical_accuracy: 0.9002\n",
      "Epoch 2501/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2342 - categorical_accuracy: 0.9335\n",
      "Epoch 2502/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2137 - categorical_accuracy: 0.9628\n",
      "Epoch 2503/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2026 - categorical_accuracy: 0.9667\n",
      "Epoch 2504/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2066 - categorical_accuracy: 0.9745\n",
      "Epoch 2505/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2977 - categorical_accuracy: 0.8748\n",
      "Epoch 2506/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1750 - categorical_accuracy: 0.9804\n",
      "Epoch 2507/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2524 - categorical_accuracy: 0.9472\n",
      "Epoch 2508/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2553 - categorical_accuracy: 0.8923\n",
      "Epoch 2509/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.4219 - categorical_accuracy: 0.8005\n",
      "Epoch 2510/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.5088 - categorical_accuracy: 0.7006\n",
      "Epoch 2511/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2876 - categorical_accuracy: 0.9139\n",
      "Epoch 2512/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2427 - categorical_accuracy: 0.9472\n",
      "Epoch 2513/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3263 - categorical_accuracy: 0.8552\n",
      "Epoch 2514/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2016 - categorical_accuracy: 0.9452\n",
      "Epoch 2515/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2863 - categorical_accuracy: 0.9315\n",
      "Epoch 2516/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.4043 - categorical_accuracy: 0.7594\n",
      "Epoch 2517/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2982 - categorical_accuracy: 0.9432\n",
      "Epoch 2518/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2754 - categorical_accuracy: 0.9374\n",
      "Epoch 2519/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1749 - categorical_accuracy: 0.9804\n",
      "Epoch 2520/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1887 - categorical_accuracy: 0.9706\n",
      "Epoch 2521/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1902 - categorical_accuracy: 0.9784\n",
      "Epoch 2522/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1918 - categorical_accuracy: 0.9550\n",
      "Epoch 2523/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2138 - categorical_accuracy: 0.9432\n",
      "Epoch 2524/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2377 - categorical_accuracy: 0.9139\n",
      "Epoch 2525/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1833 - categorical_accuracy: 0.9726\n",
      "Epoch 2526/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1783 - categorical_accuracy: 0.9706\n",
      "Epoch 2527/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1892 - categorical_accuracy: 0.9432\n",
      "Epoch 2528/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2300 - categorical_accuracy: 0.9295\n",
      "Epoch 2529/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1908 - categorical_accuracy: 0.9726\n",
      "Epoch 2530/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1606 - categorical_accuracy: 0.9765\n",
      "Epoch 2531/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1666 - categorical_accuracy: 0.9706\n",
      "Epoch 2532/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1486 - categorical_accuracy: 0.9608\n",
      "Epoch 2533/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1806 - categorical_accuracy: 0.9296\n",
      "Epoch 2534/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1953 - categorical_accuracy: 0.9530\n",
      "Epoch 2535/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.2476 - categorical_accuracy: 0.9511\n",
      "Epoch 2536/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2058 - categorical_accuracy: 0.9139\n",
      "Epoch 2537/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3210 - categorical_accuracy: 0.9022\n",
      "Epoch 2538/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.4434 - categorical_accuracy: 0.7378\n",
      "Epoch 2539/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2435 - categorical_accuracy: 0.9178\n",
      "Epoch 2540/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2602 - categorical_accuracy: 0.9197\n",
      "Epoch 2541/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.3878 - categorical_accuracy: 0.8122\n",
      "Epoch 2542/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3310 - categorical_accuracy: 0.8963\n",
      "Epoch 2543/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1761 - categorical_accuracy: 0.9765\n",
      "Epoch 2544/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2104 - categorical_accuracy: 0.9335\n",
      "Epoch 2545/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2555 - categorical_accuracy: 0.9765\n",
      "Epoch 2546/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3365 - categorical_accuracy: 0.8219\n",
      "Epoch 2547/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1840 - categorical_accuracy: 0.9432\n",
      "Epoch 2548/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1984 - categorical_accuracy: 0.9628\n",
      "Epoch 2549/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1746 - categorical_accuracy: 0.9511\n",
      "Epoch 2550/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1730 - categorical_accuracy: 0.9745\n",
      "Epoch 2551/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1848 - categorical_accuracy: 0.9530\n",
      "Epoch 2552/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1318 - categorical_accuracy: 0.9843\n",
      "Epoch 2553/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1645 - categorical_accuracy: 0.9804\n",
      "Epoch 2554/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1752 - categorical_accuracy: 0.9550\n",
      "Epoch 2555/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1236 - categorical_accuracy: 0.9784\n",
      "Epoch 2556/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1626 - categorical_accuracy: 0.9765\n",
      "Epoch 2557/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1846 - categorical_accuracy: 0.9589\n",
      "Epoch 2558/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2028 - categorical_accuracy: 0.9354\n",
      "Epoch 2559/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1697 - categorical_accuracy: 0.9726\n",
      "Epoch 2560/5000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9766"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-5f34f6297a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_12 (LSTM)               (None, 30, 64)            442112    \n_________________________________________________________________\nlstm_13 (LSTM)               (None, 30, 128)           98816     \n_________________________________________________________________\nlstm_14 (LSTM)               (None, 64)                49408     \n_________________________________________________________________\ndense_11 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_12 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_13 (Dense)             (None, 3)                 99        \n=================================================================\nTotal params: 596,675\nTrainable params: 596,675\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('B', 'B')"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "alphabets[np.argmax(res[1])],alphabets[np.argmax(y_test[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('abc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[4, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 3]],\n",
       "\n",
       "       [[4, 0],\n",
       "        [0, 1]]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, alphabets[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "B\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "A\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.7\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        # print(result)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        keypoints = get_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "\n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(alphabets[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "            # print(res[np.argmax(res)])\n",
    "\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "                    if len(sentence) > 0: \n",
    "                        if alphabets[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(alphabets[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(alphabets[np.argmax(res)])\n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            image = prob_viz(res, alphabets, image, colors)\n",
    "            \n",
    "\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}